{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Read in dataset and structure it in a way that is beneficial for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Report Grouping</th>\n      <th>Question Text</th>\n      <th>Comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Large Department</td>\n      <td>Please tell us what is working well.</td>\n      <td>we do what our customers need, we communicate ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Large Department</td>\n      <td>Please tell us what is working well.</td>\n      <td>Customs business development continues to grow...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Large Department</td>\n      <td>Please tell us what is working well.</td>\n      <td>I think the team work hard, are committed to c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Large Department</td>\n      <td>Please tell us what is working well.</td>\n      <td>Overall working towards a customer centric env...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Large Department</td>\n      <td>Please tell us what is working well.</td>\n      <td>Customer centricity is a growing culture in th...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    Report Grouping                         Question Text  \\\n0  Large Department  Please tell us what is working well.   \n1  Large Department  Please tell us what is working well.   \n2  Large Department  Please tell us what is working well.   \n3  Large Department  Please tell us what is working well.   \n4  Large Department  Please tell us what is working well.   \n\n                                            Comments  \n0  we do what our customers need, we communicate ...  \n1  Customs business development continues to grow...  \n2  I think the team work hard, are committed to c...  \n3  Overall working towards a customer centric env...  \n4  Customer centricity is a growing culture in th...  "
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "# currently reading in full dataset; small batch of data also available\n",
    "# path when running notebook via VS Code\n",
    "df = pd.read_csv(\"data/pnlp_data_en.csv\", sep=\";\")\n",
    "\n",
    "# path when running notebook via jupyter\n",
    "#df = pd.read_csv(\"../../data/pnlp_data_en.csv\", sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up dataframe into individual sets to continue processing\n",
    "large_department = df[df['Report Grouping'] == 'Large Department']\n",
    "ld_q1 = large_department[large_department['Question Text'] == 'Please tell us what is working well.']\n",
    "ld_q2 = large_department[large_department['Question Text'] == 'Please tell us what needs to be improved.']\n",
    "\n",
    "small_department = df[df['Report Grouping'] == 'Small Department']\n",
    "sd_q1 = small_department[small_department['Question Text'] == 'Please tell us what is working well.']\n",
    "sd_q2 = small_department[small_department['Question Text'] == 'Please tell us what needs to be improved.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Extract features and enrich corresponding dataframes with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0       we do what our customers need, we communicate ...\n1       Customs business development continues to grow...\n2       I think the team work hard, are committed to c...\n3       Overall working towards a customer centric env...\n4       Customer centricity is a growing culture in th...\n                              ...                        \n8018    Nothing is working well. industry standards ar...\n8019    I think the additional training has been posit...\n8020    I believe we have a good core structure, despi...\n8021    People are gaining more confidence within thei...\n8022    i enjoy working with some of the team and can ...\nName: Comments, Length: 8023, dtype: object\n"
    }
   ],
   "source": [
    "print(ld_q1['Comments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A Function for POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag(df, verbose=False, limit=-1):\n",
    "    \"\"\"\n",
    "    Extracts POS tags for every answer (important: one answer may contain multiple sentences) in a given dataframe and returns them as a list of lists.\n",
    "    Note: Function is specified for df structure of complete dataset provided by deepsight. Index adjustments might be necessary on different dfs.\n",
    "\n",
    "    df: The dataframe containing the sentences to be tagged.\n",
    "    verbose: Should the function report progress? False by default.\n",
    "    limit: If only the first n sents should be tagged, give n as limit. Tags entire df by default.\n",
    "    \"\"\"\n",
    "    # list used to store the individual lists of POS tags\n",
    "    pos_tags = []\n",
    "\n",
    "    # running index used for limit and state updates\n",
    "    i = 0\n",
    "    # set variable encoding amount of total answers to tag\n",
    "    if limit == -1:\n",
    "        end = len(df.index)\n",
    "    else:\n",
    "        end = limit\n",
    "\n",
    "    # iterature over entire dataframe\n",
    "    for row in df.iterrows():\n",
    "        # list used to store POS tags of any given answer\n",
    "        temp = []\n",
    "        # iterate over given answer\n",
    "        # adjust here for different df structures!\n",
    "        for token in nlp(row[1][2]):\n",
    "            temp.append(token.pos_)\n",
    "        # add new tags to complete list of tags\n",
    "        pos_tags.append(temp)\n",
    "\n",
    "        # defines output of verbose run of function\n",
    "        if verbose:\n",
    "            print(\"Tagging answer\", i+1, \"of\", end)\n",
    "\n",
    "        # stops function when limit is reached \n",
    "        if limit != -1:\n",
    "            if i == limit - 1: return(pos_tags)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Tagging answer 1 of 10\nTagging answer 2 of 10\nTagging answer 3 of 10\nTagging answer 4 of 10\nTagging answer 5 of 10\nTagging answer 6 of 10\nTagging answer 7 of 10\nTagging answer 8 of 10\nTagging answer 9 of 10\nTagging answer 10 of 10\nwe do what our customers need, we communicate aperiodically.\n['PRON', 'AUX', 'PRON', 'DET', 'NOUN', 'VERB', 'PUNCT', 'PRON', 'VERB', 'ADV', 'PUNCT']\n"
    }
   ],
   "source": [
    "# testing the POS tag function\n",
    "taglist = pos_tag(ld_q1, verbose=True, limit=10)\n",
    "print(ld_q1['Comments'][0])\n",
    "print(taglist[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "we do what our customers need, we communicate aperiodically.\n['PRON', 'AUX', 'PRON', 'DET', 'NOUN', 'VERB', 'PUNCT', 'PRON', 'VERB', 'ADV', 'PUNCT']\n"
    }
   ],
   "source": [
    "### A Function for Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(df, verbose=False, limit=-1):\n",
    "    \"\"\"\n",
    "    Extracts lemmas for every answer (important: one answer may contain multiple sentences) in a given dataframe and returns them as a list of lists.\n",
    "    Note: Function is specified for df structure of complete dataset provided by deepsight. Index adjustments might be necessary on different dfs.\n",
    "\n",
    "    df: The dataframe containing the sentences to be lemmatized.\n",
    "    verbose: Should the function report progress? False by default.\n",
    "    limit: If only the first n sents should be lemmatized, give n as limit. Lemmatizes entire df by default.\n",
    "    \"\"\"\n",
    "    # list used to store the individual lists of POS tags\n",
    "    lemmas = []\n",
    "\n",
    "    # running index used for limit and state updates\n",
    "    i = 0\n",
    "    # set variable encoding amount of total answers to tag\n",
    "    if limit == -1:\n",
    "        end = len(df.index)\n",
    "    else:\n",
    "        end = limit\n",
    "\n",
    "    # iterature over entire dataframe\n",
    "    for row in df.iterrows():\n",
    "        # list used to store POS tags of any given answer\n",
    "        temp = []\n",
    "        # iterate over given answer\n",
    "        # adjust here for different df structures!\n",
    "        for token in nlp(row[1][2]):\n",
    "            temp.append(token.lemma_)\n",
    "        # add new tags to complete list of tags\n",
    "        lemmas.append(temp)\n",
    "\n",
    "        # defines output of verbose run of function\n",
    "        if verbose:\n",
    "            print(\"Lemmatizing answer\", i+1, \"of\", end)\n",
    "\n",
    "        # stops function when limit is reached \n",
    "        if limit != -1:\n",
    "            if i == limit - 1: return(lemmas)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Lemmatizing answer 1 of 10\nLemmatizing answer 2 of 10\nLemmatizing answer 3 of 10\nLemmatizing answer 4 of 10\nLemmatizing answer 5 of 10\nLemmatizing answer 6 of 10\nLemmatizing answer 7 of 10\nLemmatizing answer 8 of 10\nLemmatizing answer 9 of 10\nLemmatizing answer 10 of 10\nwe do what our customers need, we communicate aperiodically.\n['-PRON-', 'do', 'what', '-PRON-', 'customer', 'need', ',', '-PRON-', 'communicate', 'aperiodically', '.']\n"
    }
   ],
   "source": [
    "# testing the POS tag function\n",
    "lemmalist = lemmatize(ld_q1, verbose=True, limit=10)\n",
    "print(ld_q1['Comments'][0])\n",
    "print(lemmalist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}