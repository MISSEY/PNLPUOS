{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in dataset and structure it in a way that is beneficial for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report Grouping</th>\n",
       "      <th>Question Text</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Large Department</td>\n",
       "      <td>Please tell us what is working well.</td>\n",
       "      <td>we do what our customers need, we communicate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Large Department</td>\n",
       "      <td>Please tell us what is working well.</td>\n",
       "      <td>Customs business development continues to grow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Large Department</td>\n",
       "      <td>Please tell us what is working well.</td>\n",
       "      <td>I think the team work hard, are committed to c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Large Department</td>\n",
       "      <td>Please tell us what is working well.</td>\n",
       "      <td>Overall working towards a customer centric env...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Large Department</td>\n",
       "      <td>Please tell us what is working well.</td>\n",
       "      <td>Customer centricity is a growing culture in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Report Grouping                         Question Text  \\\n",
       "0  Large Department  Please tell us what is working well.   \n",
       "1  Large Department  Please tell us what is working well.   \n",
       "2  Large Department  Please tell us what is working well.   \n",
       "3  Large Department  Please tell us what is working well.   \n",
       "4  Large Department  Please tell us what is working well.   \n",
       "\n",
       "                                            Comments  \n",
       "0  we do what our customers need, we communicate ...  \n",
       "1  Customs business development continues to grow...  \n",
       "2  I think the team work hard, are committed to c...  \n",
       "3  Overall working towards a customer centric env...  \n",
       "4  Customer centricity is a growing culture in th...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "# currently reading in full dataset; small batch of data also available\n",
    "# path when running notebook via VS Code\n",
    "#df = pd.read_csv(\"data/pnlp_data_en.csv\", sep=\";\")\n",
    "\n",
    "# path when running notebook via jupyter\n",
    "df = pd.read_csv(\"../../data/pnlp_data_en.csv\", sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up dataframe into individual sets to continue processing\n",
    "large_department = df[df['Report Grouping'] == 'Large Department']\n",
    "ld_q1 = large_department[large_department['Question Text'] == 'Please tell us what is working well.']\n",
    "ld_q2 = large_department[large_department['Question Text'] == 'Please tell us what needs to be improved.']\n",
    "\n",
    "small_department = df[df['Report Grouping'] == 'Small Department']\n",
    "sd_q1 = small_department[small_department['Question Text'] == 'Please tell us what is working well.']\n",
    "sd_q2 = small_department[small_department['Question Text'] == 'Please tell us what needs to be improved.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate whether Twitter-based datasets are viable as training data\n",
    "\n",
    "Idea: from initial evaluation of data, it seemed that many answers were written in an almost stream-of-consciousness style, corresponding to tweets. I will attempt to compare our dataset to the publicly available Sentiment140 dataset (http://help.sentiment140.com/for-students. To comprehend the meaning of the data, here is a description of it from the site mentioned above:\n",
    "\n",
    "0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "\n",
    "1 - the id of the tweet (2087)\n",
    "\n",
    "2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "\n",
    "3 - the query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "\n",
    "4 - the user that tweeted (robotickilldozr)\n",
    "\n",
    "5 - the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3                4  \\\n",
       "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                   5  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "s140_train = pd.read_csv(\"../../data/sentiment140_training.csv\", sep=\",\", encoding=\"latin1\", header=None)\n",
    "s140_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features and enrich corresponding dataframes with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       we do what our customers need, we communicate ...\n",
      "1       Customs business development continues to grow...\n",
      "2       I think the team work hard, are committed to c...\n",
      "3       Overall working towards a customer centric env...\n",
      "4       Customer centricity is a growing culture in th...\n",
      "                              ...                        \n",
      "8018    Nothing is working well. industry standards ar...\n",
      "8019    I think the additional training has been posit...\n",
      "8020    I believe we have a good core structure, despi...\n",
      "8021    People are gaining more confidence within thei...\n",
      "8022    i enjoy working with some of the team and can ...\n",
      "Name: Comments, Length: 8023, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ld_q1['Comments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Function for POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag(df, verbose=False, limit=-1):\n",
    "    \"\"\"\n",
    "    Extracts POS tags for every answer (important: one answer may contain multiple sentences) in a given dataframe and returns them as a list of lists.\n",
    "    Note: Function is specified for df structure of complete dataset provided by deepsight. Index adjustments might be necessary on different dfs.\n",
    "\n",
    "    df: The dataframe containing the sentences to be tagged.\n",
    "    verbose: Should the function report progress? False by default.\n",
    "    limit: If only the first n sents should be tagged, give n as limit. Tags entire df by default.\n",
    "    \"\"\"\n",
    "    # list used to store the individual lists of POS tags\n",
    "    pos_tags = []\n",
    "\n",
    "    # running index used for limit and state updates\n",
    "    i = 0\n",
    "    # set variable encoding amount of total answers to tag\n",
    "    if limit == -1:\n",
    "        end = len(df.index)\n",
    "    else:\n",
    "        end = limit\n",
    "\n",
    "    # iterature over entire dataframe\n",
    "    for row in df.iterrows():\n",
    "        # list used to store POS tags of any given answer\n",
    "        temp = []\n",
    "        # iterate over given answer\n",
    "        # adjust here for different df structures!\n",
    "        for token in nlp(row[1][2]):\n",
    "            temp.append(token.pos_)\n",
    "        # add new tags to complete list of tags\n",
    "        pos_tags.append(temp)\n",
    "\n",
    "        # defines output of verbose run of function\n",
    "        if verbose:\n",
    "            print(\"Tagging answer\", i+1, \"of\", end)\n",
    "\n",
    "        # stops function when limit is reached \n",
    "        if limit != -1:\n",
    "            if i == limit - 1: return(pos_tags)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging answer 1 of 10\n",
      "Tagging answer 2 of 10\n",
      "Tagging answer 3 of 10\n",
      "Tagging answer 4 of 10\n",
      "Tagging answer 5 of 10\n",
      "Tagging answer 6 of 10\n",
      "Tagging answer 7 of 10\n",
      "Tagging answer 8 of 10\n",
      "Tagging answer 9 of 10\n",
      "Tagging answer 10 of 10\n",
      "we do what our customers need, we communicate aperiodically.\n",
      "['PRON', 'AUX', 'PRON', 'DET', 'NOUN', 'VERB', 'PUNCT', 'PRON', 'VERB', 'ADV', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "# testing the POS tag function\n",
    "taglist = pos_tag(ld_q1, verbose=True, limit=10)\n",
    "print(ld_q1['Comments'][0])\n",
    "print(taglist[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Function for Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(df, verbose=False, limit=-1):\n",
    "    \"\"\"\n",
    "    Extracts lemmas for every answer (important: one answer may contain multiple sentences) in a given dataframe and returns them as a list of lists.\n",
    "    Note: Function is specified for df structure of complete dataset provided by deepsight. Index adjustments might be necessary on different dfs.\n",
    "\n",
    "    df: The dataframe containing the sentences to be lemmatized.\n",
    "    verbose: Should the function report progress? False by default.\n",
    "    limit: If only the first n sents should be lemmatized, give n as limit. Lemmatizes entire df by default.\n",
    "    \"\"\"\n",
    "    # list used to store the individual lists of POS tags\n",
    "    lemmas = []\n",
    "\n",
    "    # running index used for limit and state updates\n",
    "    i = 0\n",
    "    # set variable encoding amount of total answers to tag\n",
    "    if limit == -1:\n",
    "        end = len(df.index)\n",
    "    else:\n",
    "        end = limit\n",
    "\n",
    "    # iterature over entire dataframe\n",
    "    for row in df.iterrows():\n",
    "        # list used to store POS tags of any given answer\n",
    "        temp = []\n",
    "        # iterate over given answer\n",
    "        # adjust here for different df structures!\n",
    "        for token in nlp(row[1][2]):\n",
    "            temp.append(token.lemma_)\n",
    "        # add new tags to complete list of tags\n",
    "        lemmas.append(temp)\n",
    "\n",
    "        # defines output of verbose run of function\n",
    "        if verbose:\n",
    "            print(\"Lemmatizing answer\", i+1, \"of\", end)\n",
    "\n",
    "        # stops function when limit is reached \n",
    "        if limit != -1:\n",
    "            if i == limit - 1: return(lemmas)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizing answer 1 of 10\n",
      "Lemmatizing answer 2 of 10\n",
      "Lemmatizing answer 3 of 10\n",
      "Lemmatizing answer 4 of 10\n",
      "Lemmatizing answer 5 of 10\n",
      "Lemmatizing answer 6 of 10\n",
      "Lemmatizing answer 7 of 10\n",
      "Lemmatizing answer 8 of 10\n",
      "Lemmatizing answer 9 of 10\n",
      "Lemmatizing answer 10 of 10\n",
      "we do what our customers need, we communicate aperiodically.\n",
      "['-PRON-', 'do', 'what', '-PRON-', 'customer', 'need', ',', '-PRON-', 'communicate', 'aperiodically', '.']\n"
     ]
    }
   ],
   "source": [
    "# testing the POS tag function\n",
    "lemmalist = lemmatize(ld_q1, verbose=True, limit=10)\n",
    "print(ld_q1['Comments'][0])\n",
    "print(lemmalist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
